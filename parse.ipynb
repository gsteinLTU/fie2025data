{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03a5c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "\n",
    "filename = 'FIE_2025_Program_v4.pdf'\n",
    "csv_filename = 'fie_2025_papers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f7050ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns to identify key lines\n",
    "\n",
    "# Matches \"Technical Program: Monday, November 3\"\n",
    "day_pattern = re.compile(r\"Technical Program: (Monday|Tuesday|Wednesday), November (\\d+)\")\n",
    "\n",
    "# Matches e.g. \"M1-RBA: Computing Undergraduate 1: Introductory Levels\"\n",
    "session_pattern = re.compile(r\"^([A-Z]\\d+-\\w{3,4}): (.*)\")\n",
    "\n",
    "# Matches \"Room: Riverbed A\"\n",
    "room_pattern = re.compile(r\"Room: (.*)\")\n",
    "\n",
    "# Matches \"8:00\" or \"10:30\"\n",
    "time_pattern = re.compile(r\"^\\d{1,2}:\\d{2}$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a1709e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Page 25/102...\n",
      "Processing Page 26/102...\n",
      "Processing Page 27/102...\n",
      "Processing Page 28/102...\n",
      "Processing Page 29/102...\n",
      "Processing Page 30/102...\n",
      "Processing Page 31/102...\n",
      "Processing Page 32/102...\n",
      "Processing Page 33/102...\n",
      "Processing Page 34/102...\n",
      "Processing Page 35/102...\n",
      "Processing Page 36/102...\n",
      "Processing Page 37/102...\n",
      "Processing Page 38/102...\n",
      "Processing Page 39/102...\n",
      "Processing Page 40/102...\n",
      "Processing Page 41/102...\n",
      "Processing Page 42/102...\n",
      "Processing Page 43/102...\n",
      "Processing Page 44/102...\n",
      "Processing Page 45/102...\n",
      "Processing Page 46/102...\n",
      "Processing Page 47/102...\n",
      "Processing Page 48/102...\n",
      "Processing Page 49/102...\n",
      "Processing Page 50/102...\n",
      "Processing Page 51/102...\n",
      "Processing Page 52/102...\n",
      "Processing Page 53/102...\n",
      "Processing Page 54/102...\n",
      "Processing Page 55/102...\n",
      "Processing Page 56/102...\n",
      "Processing Page 57/102...\n",
      "Processing Page 58/102...\n",
      "Processing Page 59/102...\n",
      "Processing Page 60/102...\n",
      "Processing Page 61/102...\n",
      "Processing Page 62/102...\n",
      "Processing Page 63/102...\n",
      "Processing Page 64/102...\n",
      "Processing Page 65/102...\n",
      "Processing Page 66/102...\n",
      "Processing Page 67/102...\n",
      "Processing Page 68/102...\n",
      "Processing Page 69/102...\n",
      "Processing Page 70/102...\n",
      "Processing Page 71/102...\n",
      "Processing Page 72/102...\n",
      "Processing Page 73/102...\n",
      "Processing Page 74/102...\n",
      "Processing Page 75/102...\n",
      "Processing Page 76/102...\n",
      "Processing Page 77/102...\n",
      "Processing Page 78/102...\n",
      "Processing Page 79/102...\n",
      "Processing Page 80/102...\n",
      "Processing Page 81/102...\n",
      "Processing Page 82/102...\n",
      "Processing Page 83/102...\n",
      "Processing Page 84/102...\n",
      "Processing Page 85/102...\n",
      "Processing Page 86/102...\n",
      "Processing Page 87/102...\n",
      "Processing Page 88/102...\n",
      "Processing Page 89/102...\n",
      "Processing Page 90/102...\n",
      "Processing Page 91/102...\n",
      "Processing Page 92/102...\n",
      "Processing Page 93/102...\n",
      "Processing Page 94/102...\n",
      "Processing Page 95/102...\n",
      "Processing Page 96/102...\n",
      "Processing Page 97/102...\n",
      "Processing Page 98/102...\n",
      "Processing Page 99/102...\n",
      "Processing Page 100/102...\n",
      "\n",
      "Successfully extracted 587 papers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "papers_data = []\n",
    "    \n",
    "# Current state variables\n",
    "current_day = \"\"\n",
    "current_session_code = \"\"\n",
    "current_session_title = \"\"\n",
    "current_room = \"\"\n",
    "in_paper_session = False\n",
    "    \n",
    "# Temp holder for the paper being parsed\n",
    "current_paper = {}\n",
    "\n",
    "try:\n",
    "    with pdfplumber.open(filename) as pdf:\n",
    "        # The technical paper sessions start on page 25 (index 24)\n",
    "        # and end on page 100 (index 99).\n",
    "        start_page = 24\n",
    "        end_page = 99\n",
    "        \n",
    "        for page_num in range(start_page, end_page + 1):\n",
    "            page = pdf.pages[page_num]\n",
    "            \n",
    "            # Extract text line by line\n",
    "            lines = page.extract_text(x_tolerance=2, y_tolerance=2).split('\\n')\n",
    "            \n",
    "            print(f\"Processing Page {page_num + 1}/{len(pdf.pages)}...\")\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                # 1. Check for a new Day\n",
    "                day_match = day_pattern.search(line)\n",
    "                if day_match:\n",
    "                    current_day = f\"{day_match.group(1)}, Nov {day_match.group(2)}\"\n",
    "                    in_paper_session = False # Reset session on new day\n",
    "                    continue\n",
    "\n",
    "                # 2. Check for a new Session\n",
    "                session_match = session_pattern.match(line)\n",
    "                if session_match:\n",
    "                    # Before starting a new session, save the last paper\n",
    "                    # from the previous session.\n",
    "                    if current_paper:\n",
    "                        papers_data.append(current_paper)\n",
    "                        current_paper = {}\n",
    "                        \n",
    "                    new_session_code = session_match.group(1)\n",
    "                    current_session_title = session_match.group(2)\n",
    "\n",
    "                    if current_session_title.endswith(\"(cont.)\"):\n",
    "                        current_session_title = current_session_title[:-7].strip()\n",
    "                    \n",
    "                    # Check if this is a session to skip\n",
    "                    if \"Special Session\" in current_session_title or \\\n",
    "                        \"Panel Session\" in current_session_title or \\\n",
    "                        \"Focus on Exhibitors\" in current_session_title or \\\n",
    "                        \"Lunch & Keynote\" in current_session_title or \\\n",
    "                        \"Awards Luncheon\" in current_session_title:\n",
    "                        in_paper_session = False\n",
    "                    else:\n",
    "                        in_paper_session = True\n",
    "                    \n",
    "                    # Don't reset room if continuation\n",
    "                    if new_session_code != current_session_code:\n",
    "                        current_room = \"\" # Reset room\n",
    "\n",
    "                    current_session_code = new_session_code\n",
    "                    continue\n",
    "\n",
    "                # 3. Check for a Room (assumes it follows a session)\n",
    "                room_match = room_pattern.search(line)\n",
    "                if room_match and in_paper_session:\n",
    "                    current_room = room_match.group(1)\n",
    "                    continue\n",
    "\n",
    "                # 4. Check for a Paper Time\n",
    "                time_match = time_pattern.match(line)\n",
    "                if time_match and in_paper_session:\n",
    "                    # Save the previous paper's data\n",
    "                    if current_paper:\n",
    "                        papers_data.append(current_paper)\n",
    "                    \n",
    "                    # Start a new paper record\n",
    "                    current_paper = {\n",
    "                        \"Day\": current_day,\n",
    "                        \"SessionCode\": current_session_code,\n",
    "                        \"SessionTitle\": current_session_title,\n",
    "                        \"Room\": current_room,\n",
    "                        \"PaperTime\": line,\n",
    "                        \"PaperTitle\": \"\",\n",
    "                        \"Authors\": \"\"\n",
    "                    }\n",
    "                    continue\n",
    "                    \n",
    "                # 5. If we are in a paper and this is not a time/session,\n",
    "                #    it must be a title or author line.\n",
    "                if in_paper_session and current_paper:\n",
    "                    if not current_paper[\"PaperTitle\"]:\n",
    "                        # First line after time is the title\n",
    "                        current_paper[\"PaperTitle\"] = line\n",
    "                    else:\n",
    "                        # Subsequent lines are authors\n",
    "                        # Append with a space\n",
    "                        if current_paper[\"Authors\"]:\n",
    "                            current_paper[\"Authors\"] += \" \" + line\n",
    "                        else:\n",
    "                            current_paper[\"Authors\"] = line\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"'{filename}' was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Add the very last paper\n",
    "if current_paper:\n",
    "    papers_data.append(current_paper)\n",
    "\n",
    "print(f\"\\nSuccessfully extracted {len(papers_data)} papers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b90936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First paper: {'Day': 'Monday, Nov 3', 'SessionCode': 'M1-RBA', 'SessionTitle': 'Computing Undergraduate 1: Introductory Levels', 'Room': 'Riverbed A', 'PaperTime': '8:00', 'PaperTitle': 'Scaffolding the Problem-Solving Process for Introductory Computing Students', 'Authors': 'Ashish Deepak Dandekar (National University of Singapore, Singapore); Nitya Lakshmanan (NUS, Singapore); Daren Ler, Adi Yoga Sidi Prabawa and Sanka Rasnayaka (National University of Singapore, Singapore)'}\n",
      "Last paper: {'Day': 'Wednesday, Nov 5', 'SessionCode': 'W4-WPE', 'SessionTitle': 'Computer-Based Instruction 6: Immersive and Virtual Environments for Teaching and Learning', 'Room': 'Willow Pond E', 'PaperTime': '16:45', 'PaperTitle': 'Enhancing Computer Network Education Through Immersive Virtual Environments: a Study on NetVerse Edu', 'Authors': 'Erberson Evangelista Vieira (Federal Institute of Paraiba, Brazil); Francisco Petronio Alencar de Medeiros (Federal Institute of Paraiba & IFPB, Brazil); Paulo Ditarso Maciel JÃºnior (IFPB, Brazil) 100'}\n",
      "\n",
      "Unique rooms found: 8\n",
      "- Riverbed A\n",
      "- Riverbed C\n",
      "- Riverbed D\n",
      "- Willow Pond A\n",
      "- Willow Pond B\n",
      "- Willow Pond C\n",
      "- Willow Pond D\n",
      "- Willow Pond E\n"
     ]
    }
   ],
   "source": [
    "# Verify data\n",
    "if papers_data:\n",
    "    print(f\"First paper: {papers_data[0]}\")\n",
    "    print(f\"Last paper: {papers_data[-1]}\")\n",
    "else:\n",
    "    print(\"No paper data was extracted.\")\n",
    "\n",
    "unique_rooms = set(paper[\"Room\"] for paper in papers_data if paper[\"Room\"])\n",
    "print(f\"\\nUnique rooms found: {len(unique_rooms)}\")\n",
    "for room in sorted(unique_rooms):\n",
    "    print(f\"- {room}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "588ba463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to 'fie_2025_papers.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write to CSV\n",
    "if papers_data:\n",
    "    try:\n",
    "        with open(csv_filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=papers_data[0].keys())\n",
    "            writer.writeheader()\n",
    "            writer.writerows(papers_data)\n",
    "        print(f\"Data successfully written to '{csv_filename}'\")\n",
    "    except IOError:\n",
    "        print(f\"Error: Could not write to file '{csv_filename}'.\")\n",
    "else:\n",
    "    print(\"No paper data was extracted.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fie2025data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
